---
layout:     post
title:      深度学习基础之训练集、开发集和测试集
keywords:   博客
categories: [机器学习]
tags:	    [Tensorflow, GPU, 安装]
---

在实践中，为了使神经网络高效工作，我们需要不断的调整超参数和准备数据。可以说深度学习是一个高度迭代的过程：把某个想法转换为代码，实验并得到结果，分析结果改进想法，获得一个越来越好的神经网络。在这个过程中，正确的划分训练集、开发集和测试集是非常重要的。
  

## 训练集/开发集/测试集的分割法

在以前的机器学习中，通常的分割法是训练集和测试集分别占整体数据的70%和30%。如果设定了开发集(也称为交叉验证集)，那比例可能是60%/20%/20%。当样本数量是一万个样本及以下时，这个比例被广泛认为是最佳方法。

在大数据的时代，样本数量达到百万个甚至更多时，开发集和测试集在整体数据的比例就变小了，比如有100万个训练样本，那开发集和测试集只要1万个样本就足够了，比例就是98%/1%/1%。  

## 训练集/开发集/测试集的数据分布  

在实践中，训练集和测试集的数据分布往往是不匹配的。为了获取足够多的数据，训练集的数据可能是人工生成的图片，也可能是网上爬到的图片，测试集的数据则更符合实际的数据分布。

吴恩达建议的经验法则是，确保开发集和测试集中的数据分布相同。原因是我们用开发集对不同的模型进行评估，改善模型在开发集上的性能。如果开发集和测试集的数据分布相同就很方便了。即使没有测试集也是可以的，用训练集尝试不同模型结构，用开发集去评估它们，根据结果进一步迭代，由于模型拟合了开发集的数据，所以开发集不能给予无偏的估计。(测试集可以给模型无偏的估计)


## 偏差/方差

高偏差对应欠拟合，高方差对应过拟合。在训练过程中，我们可以根据训练集和开发集的数据来判断模型是欠拟合还是过拟合。

例一：训练集误差1%，开发集误差11%。这可能是模型过拟合了，模型对训练集处理得非常好，但开发集就不尽如人意，在某种程度上泛化性不好。我们将这种情况定义为高方差。

例二：训练集误差15%，开发集误差16%。模型并未对训练集数据处理得很好，就是欠拟合的。我们将这种情况定义为高偏差。  

例三：训练集误差15%，开发集误差30%。我们可以判断出这个算法是高偏差的，并且还是高方差的。

例四：训练集误差0.5%，开发集误差1%。这个算法是低偏差和低方差的，是理想的算法。

以上的前提是理想误差为0%的假设。综上，我们可以通过观察训练集的误差，知道算法是否有高偏差问题，可以通过观察开发集的误差，知道算法是否有高方差问题。


## 系统改进算法的基本准则

   

   ![](/images/images_2018/10-31_01.jpg) 






### 参考资料

